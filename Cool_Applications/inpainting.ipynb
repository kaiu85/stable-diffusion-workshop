{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "in-painting with stable diffusion using ðŸ§¨diffusers",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kaiu85/stable-diffusion-workshop/blob/main/Cool_Applications/inpainting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# In-painting pipeline for Stable Diffusion using ðŸ§¨ Diffusers \n",
        "\n",
        "This notebook shows how to do text-guided in-painting with Stable Diffusion model using  ðŸ¤— Hugging Face [ðŸ§¨ Diffusers library](https://github.com/huggingface/diffusers). \n",
        "\n",
        "For a general introduction to the Stable Diffusion model please refer to this [colab](https://colab.research.google.com/github/kaiu85/stable-diffusion-workshop/blob/main/stable_diffusion.ipynb)."
      ],
      "metadata": {
        "id": "aukP90uZv60A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, let us check again, if our instance is using a (GPU) graphics card to accelerate our computations. If yes, then !nvidia-smi should print out some informations, such as GPU type (likely Tesla T4), GPU memory (around 15GB), ... \n",
        "If this command fails, you can change the runtime settings via \"Runtime -> Change runtime type\" (German: \"Laufzeit -> Laufzeittyp Ã¤ndern\") and select \"GPU\"."
      ],
      "metadata": {
        "id": "SlltJqn2Xw4n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "Z8-ZgCvVXyZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let us install the fantastic diffusers library and some other required libraries again."
      ],
      "metadata": {
        "id": "1ej7gplLX3Tj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_khoCNOCuHNd"
      },
      "outputs": [],
      "source": [
        "!pip install -qq -U diffusers==0.6.0 transformers ftfy gradio\n",
        "!pip install git+https://github.com/huggingface/diffusers.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remember, that for in-painting, i.e. \"filling holes\" in a picture using a diffusion-model, the U-net has to be trained differently: It now also has to take the given image parts as an additional input (together with the text prompt), so that it can generate the missing parts consistently.\n",
        "\n",
        "In this post we'll use the `runwayml/stable-diffusion-inpainting` model released by Runwayml so you'll need to  visit [its Huggingface model-card](https://huggingface.co/runwayml/stable-diffusion-inpainting) while being logged-in, read the license and tick the checkbox if you agree. \n",
        "\n",
        "If you accept the license while being logged-in with an account, for which you already have created an access token, you will be able to just use this token to log into Hugging face and download the pre-trained model. You can generate new tokens and view your existing tokens here: https://huggingface.co/settings/tokens."
      ],
      "metadata": {
        "id": "qHlMV5SwwDbk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "mgCBtC7luTmk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's import the ``StableDiffusionInpaintPipeline`` and some other useful packages."
      ],
      "metadata": {
        "id": "HjswFBrMZ_K3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import inspect\n",
        "from typing import List, Optional, Union\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import gradio as gr\n",
        "from diffusers import StableDiffusionInpaintPipeline"
      ],
      "metadata": {
        "id": "dxKnZonKuYgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can generate an inpainting pipeline object and move it to the GPU ( ```\n",
        "device = \"cuda\"``)."
      ],
      "metadata": {
        "id": "LeFkJjAWaIka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\"\n",
        "model_path = \"runwayml/stable-diffusion-inpainting\"\n",
        "\n",
        "pipe = StableDiffusionInpaintPipeline.from_pretrained(\n",
        "    model_path,\n",
        "    revision=\"fp16\", \n",
        "    torch_dtype=torch.float16,\n",
        "    use_auth_token=True\n",
        ").to(device)"
      ],
      "metadata": {
        "id": "MfUEmooNuyKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As in previous notebooks, we define a helper function \"image_grid\", which just lets us display multiple images in a nice grid view."
      ],
      "metadata": {
        "id": "qo2RKUfAaWEw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "def image_grid(imgs, rows, cols):\n",
        "    assert len(imgs) == rows*cols\n",
        "\n",
        "    w, h = imgs[0].size\n",
        "    grid = PIL.Image.new('RGB', size=(cols*w, rows*h))\n",
        "    grid_w, grid_h = grid.size\n",
        "    \n",
        "    for i, img in enumerate(imgs):\n",
        "        grid.paste(img, box=(i%cols*w, i//cols*h))\n",
        "    return grid"
      ],
      "metadata": {
        "id": "hvdHYdtTu6KA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the next code cells, we download an image and a mask image. The mask image tells the pipeline, which pixels of the image should be replaced by samples from the latent-diffusion model (white) and which pixels should be kept (black)."
      ],
      "metadata": {
        "id": "R20ngdsVad4c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dowload the image\n",
        "!wget https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo.png"
      ],
      "metadata": {
        "id": "tH2Mbw_aaeEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess and display the image\n",
        "filename = 'overture-creations-5sI6fQgYIuo.png'\n",
        "\n",
        "image = Image.open(filename).convert(\"RGB\")\n",
        "image = image.resize((512, 512))\n",
        "image"
      ],
      "metadata": {
        "id": "-viNotlybQMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the mask image\n",
        "!wget https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo_mask.png"
      ],
      "metadata": {
        "id": "y4OVr7pPvMWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess and display the mask image\n",
        "filename = 'overture-creations-5sI6fQgYIuo_mask.png'\n",
        "\n",
        "mask_image = Image.open(filename).convert(\"RGB\")\n",
        "mask_image = mask_image.resize((512, 512))\n",
        "mask_image"
      ],
      "metadata": {
        "id": "GSdamba-vo0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remember that the mask image tells the pipeline, which pixels of the image should be replaced (white) and which pixels should be kept (black)."
      ],
      "metadata": {
        "id": "GVCCOLuLbrdy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's define a prompt, which guides the generation process and see, how the generated results look like for three (``num_samples``) samples."
      ],
      "metadata": {
        "id": "udz0RJosby-f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"a tucan sitting on a bench\"\n",
        "\n",
        "guidance_scale=7.5\n",
        "num_samples = 3\n",
        "generator = torch.Generator(device=\"cuda\").manual_seed(0) # change the seed to get different results\n",
        "\n",
        "images = pipe(\n",
        "    prompt=prompt,\n",
        "    image=image,\n",
        "    mask_image=mask_image,\n",
        "    guidance_scale=guidance_scale,\n",
        "    generator=generator,\n",
        "    num_images_per_prompt=num_samples,\n",
        ").images"
      ],
      "metadata": {
        "id": "OkePC-DGvyz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To compare the in-painted images with the original image, we add the original images as first item to the list ``images``."
      ],
      "metadata": {
        "id": "KUtSf6t9cZna"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# insert initial image in the list so we can compare side by side\n",
        "images.insert(0, image)"
      ],
      "metadata": {
        "id": "WtfJyo1XhBP8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we display the list of images using our ``image_grid`` function (with a single row)."
      ],
      "metadata": {
        "id": "uSxP30lcckr8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_grid(images, 1, num_samples + 1)"
      ],
      "metadata": {
        "id": "loXzMOIxv9OZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To work with your own images, you can just open the file explorer on the left (![BildschirmÂ­foto 2022-11-17 um 17.37.59.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABcAAAAkCAYAAABixKGjAAABU2lDQ1BJQ0MgUHJvZmlsZQAAGJV1kD9Lw1AUxU80UrEiio6CGUQqVNFUNxFqh1IUCa3/cUnTmAppfCZREb+Ag4KTk+Dm3EHopDj4DRSVDo6uDkIWLfG+Rm2q+B6X8+NwuBwu0AKVMVMEULJcO5uekVZW16TIC6Lood+OcVVzWFJR5iiCb21+3gMErncjfNflbux8/uD1KL00uz19UvX+5pteR0F3NNIPmpjGbBcQBomVPZdxpkGfTaWIDzkbAZ9xzgdcrmcWsiniW+JuragWiO+J4/mQb4S4ZO5oXx14+07dWsxxpelHBgpykJHA5D+5iXouhS0w7MPGJgwU4UJCkhwGEzpxBhY0jCJOLGOMRub3/X23huc8AVO0Wwzl1geA8hVVPm54Q89AbxdwbTHVVn+uKXiis5GQA45WgLZT339bBiLDQO3R998rvl+7AFqrwI33CRIQYb3DFBkQAAAAVmVYSWZNTQAqAAAACAABh2kABAAAAAEAAAAaAAAAAAADkoYABwAAABIAAABEoAIABAAAAAEAAAAXoAMABAAAAAEAAAAkAAAAAEFTQ0lJAAAAU2NyZWVuc2hvdDeLFh0AAAHUaVRYdFhNTDpjb20uYWRvYmUueG1wAAAAAAA8eDp4bXBtZXRhIHhtbG5zOng9ImFkb2JlOm5zOm1ldGEvIiB4OnhtcHRrPSJYTVAgQ29yZSA2LjAuMCI+CiAgIDxyZGY6UkRGIHhtbG5zOnJkZj0iaHR0cDovL3d3dy53My5vcmcvMTk5OS8wMi8yMi1yZGYtc3ludGF4LW5zIyI+CiAgICAgIDxyZGY6RGVzY3JpcHRpb24gcmRmOmFib3V0PSIiCiAgICAgICAgICAgIHhtbG5zOmV4aWY9Imh0dHA6Ly9ucy5hZG9iZS5jb20vZXhpZi8xLjAvIj4KICAgICAgICAgPGV4aWY6UGl4ZWxZRGltZW5zaW9uPjM2PC9leGlmOlBpeGVsWURpbWVuc2lvbj4KICAgICAgICAgPGV4aWY6UGl4ZWxYRGltZW5zaW9uPjIzPC9leGlmOlBpeGVsWERpbWVuc2lvbj4KICAgICAgICAgPGV4aWY6VXNlckNvbW1lbnQ+U2NyZWVuc2hvdDwvZXhpZjpVc2VyQ29tbWVudD4KICAgICAgPC9yZGY6RGVzY3JpcHRpb24+CiAgIDwvcmRmOlJERj4KPC94OnhtcG1ldGE+CqJcsIgAAAC/SURBVEgN7ZZtCsMgDIbt2GXU6ygeUq+jHmdtCgqLb10L64+NBMSSjzf0aZQur83UTfa4SXeXFXFIV7AIFkgAOmVa/gzLk79PKYW7lDFm8J1xvImHEGCNc05572Fs5uziMcbDvJSSqrUexrXWsHkXb5XW2vZ4eqfmVMfxDeKEgCfNutA3yjnvi9fJCYXkBAvE0keR5pTmlcbqis3yu3gTpAa0rhq6Hhb+I4ourk+N+OFp+YN4C3xjl1GEFH8XywqiOjbStu0P4AAAAABJRU5ErkJggg==)-Icon) and upload (![BildschirmÂ­foto 2022-11-17 um 17.42.25.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABsAAAAcCAYAAACQ0cTtAAABU2lDQ1BJQ0MgUHJvZmlsZQAAGJV1kD9Lw1AUxU80UrEiio6CGUQqVNFUNxFqh1IUCa3/cUnTmAppfCZREb+Ag4KTk+Dm3EHopDj4DRSVDo6uDkIWLfG+Rm2q+B6X8+NwuBwu0AKVMVMEULJcO5uekVZW16TIC6Lood+OcVVzWFJR5iiCb21+3gMErncjfNflbux8/uD1KL00uz19UvX+5pteR0F3NNIPmpjGbBcQBomVPZdxpkGfTaWIDzkbAZ9xzgdcrmcWsiniW+JuragWiO+J4/mQb4S4ZO5oXx14+07dWsxxpelHBgpykJHA5D+5iXouhS0w7MPGJgwU4UJCkhwGEzpxBhY0jCJOLGOMRub3/X23huc8AVO0Wwzl1geA8hVVPm54Q89AbxdwbTHVVn+uKXiis5GQA45WgLZT339bBiLDQO3R998rvl+7AFqrwI33CRIQYb3DFBkQAAAAVmVYSWZNTQAqAAAACAABh2kABAAAAAEAAAAaAAAAAAADkoYABwAAABIAAABEoAIABAAAAAEAAAAboAMABAAAAAEAAAAcAAAAAEFTQ0lJAAAAU2NyZWVuc2hvdHZ6LUgAAAHUaVRYdFhNTDpjb20uYWRvYmUueG1wAAAAAAA8eDp4bXBtZXRhIHhtbG5zOng9ImFkb2JlOm5zOm1ldGEvIiB4OnhtcHRrPSJYTVAgQ29yZSA2LjAuMCI+CiAgIDxyZGY6UkRGIHhtbG5zOnJkZj0iaHR0cDovL3d3dy53My5vcmcvMTk5OS8wMi8yMi1yZGYtc3ludGF4LW5zIyI+CiAgICAgIDxyZGY6RGVzY3JpcHRpb24gcmRmOmFib3V0PSIiCiAgICAgICAgICAgIHhtbG5zOmV4aWY9Imh0dHA6Ly9ucy5hZG9iZS5jb20vZXhpZi8xLjAvIj4KICAgICAgICAgPGV4aWY6UGl4ZWxZRGltZW5zaW9uPjI4PC9leGlmOlBpeGVsWURpbWVuc2lvbj4KICAgICAgICAgPGV4aWY6UGl4ZWxYRGltZW5zaW9uPjI3PC9leGlmOlBpeGVsWERpbWVuc2lvbj4KICAgICAgICAgPGV4aWY6VXNlckNvbW1lbnQ+U2NyZWVuc2hvdDwvZXhpZjpVc2VyQ29tbWVudD4KICAgICAgPC9yZGY6RGVzY3JpcHRpb24+CiAgIDwvcmRmOlJERj4KPC94OnhtcG1ldGE+CkKYPr0AAAEVSURBVEgN7ZZRDoMgDIZx2WnwOhrPSPQ6ep1tv0mXFhBaND4s64NgafvZUti610fcTfK4ibNjfhf25GXcts0ty+LWdeXqZD4MgxvHMdHXFKKMGhACwm6e51rsZF1kRhmFEBJDUkzTtE8BhFgyFJnt3oaHNcNTMHyXBXgaZgFeAiMgxpKIBikZ0lqueahpyOZovCyzIwDXq2E4Vy1ni8NUZQSEzhWcLWeLw6qZxSBLq3MQ5kVYDCLnVmARRsFx8ZLwOem0Y3HPsDd93zvv/XfPuE4LIbtqZgDFktPFNrn3Kizn1KorlpEHzd0cfF0zFzDsD37TtNcPB8C3JqKM6DSNUxwUPpou7f7/G+PStbyLPWsJYPF5A6jwXuPXwH0TAAAAAElFTkSuQmCC)-Icon) your own image and mask image files and change the filenames in the above cells accordingly."
      ],
      "metadata": {
        "id": "qQqD3aZtcyq4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "However, creating the mask files require you to use some image editing software ([GIMP](https://www.gimp.org) is a great, free and open source image editing software, but takes some time to learn).\n",
        "\n",
        "Thus, to make experimenting with your own images easier and more fun, we will use the ``gradio`` package in the next few cells, to generate a **graphical user interface**, which lets you upload images and mask them easily."
      ],
      "metadata": {
        "id": "MWR0-3UNe3fu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Interactive Gradio Demo"
      ],
      "metadata": {
        "id": "ZupJ7HzIzRQ5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we install the gradio package and import it as ``gr``."
      ],
      "metadata": {
        "id": "tssGcMPzgNM4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gradio\n",
        "import gradio as gr"
      ],
      "metadata": {
        "id": "E1YB1GmxgRhb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradio needs a function, which it can call to generate an inpainted image, based on an image, a mask image, and a prompt. Thus, we define such a function in the next cell."
      ],
      "metadata": {
        "id": "Km4UQhs6fh5i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(dict, prompt):\n",
        "  image =  dict['image'].convert(\"RGB\").resize((512, 512))\n",
        "  mask_image = dict['mask'].convert(\"RGB\").resize((512, 512))\n",
        "  images = pipe(prompt=prompt, image=image, mask_image=mask_image).images\n",
        "  return(images[0])"
      ],
      "metadata": {
        "id": "byoa1q2zyd6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next few lines of code just create a very simple user interface, where you can upload and mask an image (``gr.Image``) and add a text prompt (``gr.Textbox``)."
      ],
      "metadata": {
        "id": "YDcL_2e1fr0r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gr.Interface(\n",
        "    predict,\n",
        "    title = 'Stable Diffusion In-Painting',\n",
        "    inputs=[\n",
        "        gr.Image(source = 'upload', tool = 'sketch', type = 'pil'),\n",
        "        gr.Textbox(label = 'prompt')\n",
        "    ],\n",
        "    outputs = [\n",
        "        gr.Image()\n",
        "        ]\n",
        ").launch(debug=True)"
      ],
      "metadata": {
        "id": "R596bpT2ynqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment\n",
        "\n",
        "Again, please take your time to **play with the model**. Try different input images, try masking out different regions, and see how a prompt can change the inpainted results. Try also **filling the mask regions with an empty ('') prompt**. This way you can explore, what your model expects to be in the masked-out regions, when it is not guided by an additional text prompt.\n",
        "\n",
        "**Please** collect suprisingly good, suprisingly bad, funny and interesting results [here](https://docs.google.com/presentation/d/1n5P9JIyYoISbRIfRgXvwmXFdETlPm1FQ_S7WuqKgqBo/edit?usp=sharing). Feel free to also add links, thoughts and comments, which you want to share with the group."
      ],
      "metadata": {
        "id": "ccz-I8e4h5lg"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z4jHBYgfiSdK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}