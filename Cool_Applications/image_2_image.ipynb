{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image-2-image using diffusers",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kaiu85/stable-diffusion-workshop/blob/main/Cool_Applications/image_2_image.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image2Image Pipeline for Stable Diffusion using ðŸ§¨ Diffusers \n",
        "\n",
        "This notebook shows how to create a custom `diffusers` pipeline for  text-guided image-to-image generation with Stable Diffusion model using  ðŸ¤— Hugging Face [ðŸ§¨ Diffusers library](https://github.com/huggingface/diffusers). \n",
        "\n",
        "For a general introduction to the Stable Diffusion model please refer to this [colab](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/stable_diffusion.ipynb).\n",
        "\n"
      ],
      "metadata": {
        "id": "846pN2uHGJLx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L52bmJXkAMQz"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install diffusers==0.3.0 transformers ftfy\n",
        "!pip install -qq \"ipywidgets>=7,<8\""
      ],
      "metadata": {
        "id": "n9AmMcAGASDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You need to accept the model license before downloading or using the weights. In this post we'll use model version `v1-4`, so you'll need to  visit [its card](https://huggingface.co/CompVis/stable-diffusion-v1-4), read the license and tick the checkbox if you agree. \n",
        "\n",
        "You have to be a registered user in ðŸ¤— Hugging Face Hub, and you'll also need to use an access token for the code to work. For more information on access tokens, please refer to [this section of the documentation](https://huggingface.co/docs/hub/security-tokens)."
      ],
      "metadata": {
        "id": "DQ11k9JVIXII"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remember, you can create and find your Huggingface tokens \n",
        "at https://huggingface.co/settings/tokens.\n",
        "Alternatively, you can log into your Huggingface.co account,\n",
        "click on your profile picture on the upper right\n",
        "and then navigating to \"Settings -> Access Tokens\"."
      ],
      "metadata": {
        "id": "ySeWp94B1eDW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "AOe3MmjoAoSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image2Image pipeline."
      ],
      "metadata": {
        "id": "Uclfq60nIQvm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import inspect\n",
        "import warnings\n",
        "from typing import List, Optional, Union\n",
        "\n",
        "import torch\n",
        "from torch import autocast\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "from diffusers import StableDiffusionImg2ImgPipeline"
      ],
      "metadata": {
        "id": "2YJrHBHlB54B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the pipeline"
      ],
      "metadata": {
        "id": "YL179UtGKweb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\"\n",
        "model_path = \"CompVis/stable-diffusion-v1-4\"\n",
        "\n",
        "pipe = StableDiffusionImg2ImgPipeline.from_pretrained(\n",
        "    model_path,\n",
        "    revision=\"fp16\", \n",
        "    torch_dtype=torch.float16,\n",
        "    use_auth_token=True\n",
        ")\n",
        "pipe = pipe.to(device)"
      ],
      "metadata": {
        "id": "Fr2QIEzvCFH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download an initial image and preprocess it so we can pass it to the pipeline."
      ],
      "metadata": {
        "id": "tFBvRqfCKzVQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/CompVis/stable-diffusion/main/assets/stable-samples/img2img/sketch-mountains-input.jpg\"\n",
        "\n",
        "response = requests.get(url)\n",
        "init_img = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
        "init_img = init_img.resize((768, 512))\n",
        "init_img"
      ],
      "metadata": {
        "id": "quipipaCC1AP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the prompt and run the pipeline."
      ],
      "metadata": {
        "id": "XgtE5Qn9LE1m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Photograph of a fantasy landscape, highest quality, DSLR.\""
      ],
      "metadata": {
        "id": "4V11Z0l-ZUWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, `strength` is a value between 0.0 and 1.0, that controls the amount of noise that is added to the input image. Values that approach 1.0 allow for lots of variations but will also produce images that are not semantically consistent with the input."
      ],
      "metadata": {
        "id": "8wOmwKnkDfpd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generator = torch.Generator(device=device).manual_seed(1024)\n",
        "with autocast(\"cuda\"):\n",
        "    image = pipe(prompt=prompt, init_image=init_img, strength=0.99, guidance_scale=7.5, generator=generator).images[0]"
      ],
      "metadata": {
        "id": "V24njWQBC8eC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image"
      ],
      "metadata": {
        "id": "uMfaTT24DWk6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with autocast(\"cuda\"):\n",
        "    image = pipe(prompt=prompt, init_image=init_img, strength=0.5, guidance_scale=7.5, generator=generator).images[0]"
      ],
      "metadata": {
        "id": "Rfn_M2f9Dsl1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image"
      ],
      "metadata": {
        "id": "JlUXXh7MEFPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, when using a lower value for `strength`, the generated image is more closer to the original `init_image`"
      ],
      "metadata": {
        "id": "NlQlTZDIEQKi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Now using [LMSDiscreteScheduler](https://huggingface.co/docs/diffusers/api/schedulers#diffusers.LMSDiscreteScheduler)"
      ],
      "metadata": {
        "id": "kpBvfS4oVv9K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from diffusers import LMSDiscreteScheduler\n",
        "\n",
        "lms = LMSDiscreteScheduler(beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\")\n",
        "pipe.scheduler = lms"
      ],
      "metadata": {
        "id": "0O0Iy1zK0q-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = torch.Generator(device=device).manual_seed(1024)\n",
        "with autocast(\"cuda\"):\n",
        "    image = pipe(prompt=prompt, init_image=init_img, strength=0.75, guidance_scale=7.5, generator=generator).images[0]"
      ],
      "metadata": {
        "id": "q7ixTMhfD6Ux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image"
      ],
      "metadata": {
        "id": "Tm_SR0gT0s2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interaktive Demo"
      ],
      "metadata": {
        "id": "qAqBD1syNmZI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gradio\n",
        "import gradio as gr"
      ],
      "metadata": {
        "id": "oshPuezlNoM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(image, prompt, strength, guidance_scale):\n",
        "  init_img =  image.convert(\"RGB\").resize((512, 512))\n",
        "  with autocast(\"cuda\"):\n",
        "    images = pipe(prompt=prompt, init_image=init_img, strength=strength, guidance_scale=guidance_scale).images\n",
        "  return(images[0])"
      ],
      "metadata": {
        "id": "6EaGYhOUP89R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr.Interface(\n",
        "    predict,\n",
        "    title = 'Stable Diffusion Image-2-Image',\n",
        "    inputs=[\n",
        "        gr.Paint(type = 'pil', shape = (512, 512)), # USE THIS LINE TO DRAW ON AN EMPTY CANVAS\n",
        "        #gr.ImagePaint(type = 'pil'), # USE THIS LINE to first UPLOAD and IMAGE and then (optionally) draw on it\n",
        "        gr.Textbox(label = 'prompt', value = ''),\n",
        "        gr.Number(label = 'noise strength', value = 0.75),\n",
        "        gr.Number(label = 'guidance scale', value = 7.5)\n",
        "    ],\n",
        "    outputs = [\n",
        "        gr.Image()\n",
        "        ]\n",
        ").launch(debug=True)"
      ],
      "metadata": {
        "id": "PNcQOKw-PRAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Sm0wlj1jOWTx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}